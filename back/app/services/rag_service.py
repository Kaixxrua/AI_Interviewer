# app/services/rag_service.py

import os
import chromadb

# üü¢ 1. ÂºïÂÖ• Chroma Ëá™Â∏¶ÁöÑ embedding Â∑•ÂÖ∑
from chromadb.utils import embedding_functions
from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
import pypdf

load_dotenv()

# ÂàùÂßãÂåñ ChromaDB
chroma_client = chromadb.PersistentClient(path="./chroma_db")

# üî•üî•üî• ‰øùÊåÅ‰Ω†ÈÄâÊã©ÁöÑ BAAI Êú¨Âú∞Ê®°Âûã‰∏çÂèò üî•üî•üî•
MODEL_NAME = "BAAI/bge-small-zh-v1.5"

# ËÆæÁΩÆ HuggingFace ÈïúÂÉè (Èò≤‰∏ãËΩΩÂç°È°ø)
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"

local_embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
    model_name=MODEL_NAME
)

# Ëé∑Âèñ/ÂàõÂª∫ÈõÜÂêà
collection = chroma_client.get_or_create_collection(
    name="interview_knowledge_base_local",
    embedding_function=local_embedding_fn,
)


def extract_text_from_file(file_path: str) -> str:
    ext = os.path.splitext(file_path)[1].lower()
    text_content = ""
    try:
        if ext == ".pdf":
            reader = pypdf.PdfReader(file_path)
            for page in reader.pages:
                text_content += page.extract_text() + "\n"
        else:
            with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                text_content = f.read()
        return text_content
    except Exception as e:
        print(f"‚ùå Ëß£ÊûêÂ§±Ë¥• {file_path}: {e}")
        return ""


def add_document_to_kb(file_path: str, source_name: str):
    text = extract_text_from_file(file_path)
    if not text or len(text) < 10:
        return 0

    splitter = RecursiveCharacterTextSplitter(chunk_size=600, chunk_overlap=100)
    chunks = splitter.split_text(text)

    if not chunks:
        return 0

    ids = [f"{source_name}_{i}" for i in range(len(chunks))]
    metadatas = [{"source": source_name} for _ in chunks]

    collection.add(documents=chunks, ids=ids, metadatas=metadatas)
    print(f"‚úÖ ÊàêÂäüÂØºÂÖ•: {source_name} (ÂÖ± {len(chunks)} ‰∏™ÂàáÁâá)")
    return len(chunks)


def list_documents_in_kb():
    try:
        all_data = collection.get(include=["metadatas"])
        file_stats = {}
        for meta in all_data["metadatas"]:
            source_name = meta.get("source", "Unknown")
            file_stats[source_name] = file_stats.get(source_name, 0) + 1
        result = []
        for name, count in file_stats.items():
            result.append({"filename": name, "chunks_count": count})
        return result
    except Exception as e:
        print(f"Êü•ËØ¢ÂàóË°®Â§±Ë¥•: {e}")
        return []


# üî•üî•üî• Ê†∏ÂøÉ‰øÆÂ§çÔºöÂ¢ûÂä†ÈòàÂÄºËøáÊª§ üî•üî•üî•
def search_knowledge(query: str, top_k: int = 3):
    try:
        # ChromaDB ÈªòËÆ§ËøîÂõû distances (Ë∑ùÁ¶ª)ÔºåË∂äÂ∞èË∂äÁõ∏‰ºº
        results = collection.query(query_texts=[query], n_results=top_k)

        valid_documents = []
        if results["distances"]:
            for i, dist in enumerate(results["distances"][0]):
                # üü¢ ÈòàÂÄºÊéßÂà∂Ôºö0.6 ÊòØ‰∏Ä‰∏™ÁªèÈ™åÂÄº
                # Â¶ÇÊûúË∑ùÁ¶ªÂ§ß‰∫é 0.6ÔºåËØ¥ÊòéÂÜÖÂÆπÈ£éÈ©¨Áâõ‰∏çÁõ∏ÂèäÔºàÊØîÂ¶ÇÊêúPythonÂá∫‰∫ÜJavaÔºâÔºåÁõ¥Êé•‰∏¢ÂºÉ
                if dist < 0.6:
                    valid_documents.append(results["documents"][0][i])
                else:
                    # ÂèØ‰ª•Âú®ËøôÈáåÊâìÂç∞Êó•ÂøóÁúãÁúãË¢´ËøáÊª§ÊéâÁöÑÂÜÖÂÆπ
                    # print(f"ËøáÊª§‰ΩéÁõ∏ÂÖ≥ÊñáÊ°£ (dist={dist}): {results['documents'][0][i][:10]}...")
                    pass

        return valid_documents
    except Exception as e:
        print(f"RAG Search Error: {e}")
        return []
